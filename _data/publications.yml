- title: "DocIE@XLLM25: In-Context Learning for Information Extraction using Fully Synthetic Demonstrations"
  authors: "<u>Nicholas Popovič</u>, Ashish Kangen, Tim Schopf, Michael Färber"
  year: "2025"
  venue: "XLLM @ ACL (workshop)"
  pdf_link: "https://aclanthology.org/2025.xllm-1.26.pdf"
  type: "workshop"
  spotlight: false
  code_link: "https://github.com/nicpopovic/docie-xllm25"
  video_link: "https://webresources1234.s3.eu-north-1.amazonaws.com/docie.m4v"
  "link": "/publications/docie"
  abstract: "Large, high-quality annotated corpora remain scarce in document-level entity and relation extraction in zero-shot or few-shot settings.In this paper, we present a fully automatic, LLM-based pipeline for synthetic data generation and in-context learning for document-level entity and relation extraction.In contrast to existing approaches that rely on manually annotated demonstrations or direct zero-shot inference, our method combines synthetic data generation with retrieval-based in-context learning, using a reasoning-optimized language model.This allows us to build a high-quality demonstration database without manual annotation and to dynamically retrieve relevant examples at inference time.Based on our approach we produce a synthetic dataset of over 5k Wikipedia abstracts with approximately 59k entities and 30k relation triples.Finally, we evaluate in-context learning performance on the DocIE shared task, extracting entities and relations from long documents in a zero-shot setting.The code and synthetic dataset are made available for future research."
  tldr: "Synthetic data generation for schema constrained information extraction tasks. Dataset with 5k annotated articles available for future research."


- title: "Kaleidoscope: In-language Exams for Massively Multilingual Vision Evaluation"
  authors: "Salazar et al."
  year: "2025"
  venue: "preprint"
  pdf_link: "https://arxiv.org/pdf/2504.07072"
  type: "long"
  spotlight: false
  
- title: "The Effects of Hallucinations in Synthetic Training Data for Relation Extraction"
  authors: "Steven Rogulsky, <u>Nicholas Popovič</u>, Michael Färber"
  year: "2024"
  venue: "KBC-LM @ ISWC (workshop)"
  pdf_link: "https://arxiv.org/pdf/2410.08393"
  type: "workshop"
  spotlight: false

- title: "Embedded Named Entity Recognition using Probing Classifiers"
  authors: "<u>Nicholas Popovič</u>, Michael Färber"
  year: "2024"
  venue: "EMNLP"
  pdf_link: "https://aclanthology.org/2024.emnlp-main.988.pdf"
  type: "long"
  spotlight: true
  image: "/images/ember-spotlight.gif"
  code_link: "https://github.com/nicpopovic/STOKE"
  abstract: "Streaming text generation, has become a common way of increasing the responsiveness of language model powered applications such as chat assistants. At the same time, extracting semantic information from generated text is a useful tool for applications such as automated fact checking or retrieval augmented generation. Currently, this requires either separate models during inference, which increases computational cost, or destructive fine-tuning of the language model. Instead, we propose an approach called EMBER which enables streaming named entity recognition in decoder-only language models without fine-tuning them and while incurring minimal additional computational cost at inference time. Specifically, our experiments show that EMBER maintains high token generation rates, with only a negligible decrease in speed of around 1% compared to a 43.64% slowdown measured for a baseline. We make our code and data available online, including a toolkit for training, testing, and deploying efficient token classification models optimized for streaming text generation."
  tldr: "A light-weight method for extracting named entities from generated text during streaming text generation with language models."
  "link": "/publications/ember"
  "video_link": "https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2024-10-28/dd133a2/EMBER%20EMNLP%20presentation.mp4"

- title: "VOCAB-EXPANDER: A System for Creating Domain-Specific Vocabularies Based on Word Embeddings"
  authors: "Michael Färber, <u>Nicholas Popovič</u>"
  year: "2023"
  venue: "RANLP (demo)"
  pdf_link: "https://aclanthology.org/2023.ranlp-1.37.pdf"
  type: "demo"
  spotlight: false
  demo_link: "https://vocab-expander.com"
  code_link: "https://github.com/nicpopovic/VocabExpander"

- title: "Towards solving fuzzy tasks with human feedback: A retrospective of the minerl basalt 2022 competition"
  authors: "Milani et al."
  year: "2022"
  venue: "Competitions Track @ NeurIPS (workshop)"
  pdf_link: "https://proceedings.mlr.press/v220/milani23a/milani23a.pdf"
  type: "workshop"
  spotlight: false
  code_link: "https://github.com/BASALT-2022-Karlsruhe/ka-basalt-2022"

- title: "Few-Shot Document-Level Relation Extraction"
  authors: "<u>Nicholas Popovič</u>, Michael Färber"
  year: "2022"
  venue: "NAACL"
  pdf_link: "https://aclanthology.org/2022.naacl-main.421.pdf"
  type: "long"
  spotlight: true
  image: "/images/fredo-spotlight.jpg"
  code_link: "https://github.com/nicpopovic/FREDo"
  abstract: "We present FREDo, a few-shot document-level relation extraction (FSDLRE) benchmark. As opposed to existing benchmarks which are built on sentence-level relation extraction corpora, we argue that document-level corpora provide more realism, particularly regarding none-of-the-above (NOTA) distributions. Therefore, we propose a set of FSDLRE tasks and construct a benchmark based on two existing supervised learning data sets, DocRED and sciERC. We adapt the state-of-the-art sentence-level method MNAV to the document-level and develop it further for improved domain adaptation. We find FSDLRE to be a challenging setting with interesting new characteristics such as the ability to sample NOTA instances from the support set. The data, code, and trained models are available online (https://github.com/nicpopovic/FREDo)."
  tldr: "A document-level benchmark for few-shot relation extraction. More realistic, more difficult."
  "link": "/publications/fredo"
  video_link: "https://aclanthology.org/2022.naacl-main.421.mp4"

- title: "AIFB-WebScience at SemEval-2022 Task 12: Relation Extraction First - Using Relation Extraction to Identify Entities"
  authors: "<u>Nicholas Popovič</u>, Walter Laurito, Michael Färber"
  year: "2022"
  venue: "SemEval @ NAACL (workshop)"
  pdf_link: "https://aclanthology.org/2022.semeval-1.232.pdf"
  type: "workshop"
  spotlight: false
  code_link: "https://github.com/nicpopovic/RE1st"
  video_link: "https://s3.amazonaws.com/pf-user-files-01/u-59356/uploads/2022-06-22/id432q3/semeval1080.mp4"
  "link": "/publications/re1st"
  abstract: "In this paper, we present an end-to-end joint entity and relation extraction approach based on transformer-based language models. We apply the model to the task of linking mathematical symbols to their descriptions in LaTeX documents. In contrast to existing approaches, which perform entity and relation extraction in sequence, our system incorporates information from relation extraction into entity extraction. This means that the system can be trained even on data sets where only a subset of all valid entity spans is annotated. We provide an extensive evaluation of the proposed system and its strengths and weaknesses. Our approach, which can be scaled dynamically in computational complexity at inference time, produces predictions with high precision and reaches 3rd place in the leaderboard of SemEval-2022 Task 12. For inputs in the domain of physics and math, it achieves high relation extraction macro F1 scores of 95.43% and 79.17%, respectively. The code used for training and evaluating our models is available at: https://github.com/nicpopovic/RE1st"
  tldr: "An end-to-end joint entity and relation extraction approach applied to linking mathematical symbols to their descriptions in LaTeX documents."


- title: "Which Publications’ Metadata Are in Which Bibliographic Databases? A System for Exploration"
  authors: "Michael Färber, Christoph Braun, <u>Nicholas Popovič</u>, Tarek Saier, Kristian Noullet"
  year: "2022"
  venue: "BIR @ ECIR (demo)"
  pdf_link: "https://www.researchgate.net/profile/Michael_Faerber/publication/366634843_Which_Publications'_Metadata_Are_in_Which_Bibliographic_Databases_A_System_for_Exploration/links/63ac10b2c3c99660ebae12b5/Which-Publications-Metadata-Are-in-Which-Bibliographic-Databases-A-System-for-Exploration.pdf"
  type: "demo"
  spotlight: false
  code_link: "https://github.com/kmdn/RefBee"

- title: "Ampacity forecasting from numerical weather predictions: a fusion of the traditional and machine learning methods"
  authors: "Gabriela Molinar, Johannes Bassler, <u>Nicholas Popovič</u>, Wilhelm Stork"
  year: "2020"
  venue: "IEEE ISGT-Europe"
  pdf_link: "https://ieeexplore.ieee.org/abstract/document/9248877"
  type: "long"
  spotlight: false

- title: "From data points to ampacity forecasting: Gated recurrent unit networks"
  authors: "<u>Nicholas Popovič</u>, Gabriela Molinar, Wilhelm Stork"
  year: "2018"
  venue: "IEEE BigDataService"
  pdf_link: "https://www.researchgate.net/profile/Gabriela-Molinar/publication/326279992_From_Data_Points_to_Ampacity_Forecasting_Gated_Recurrent_Unit_Networks/links/5b5eb625aca272a2d67464da/From-Data-Points-to-Ampacity-Forecasting-Gated-Recurrent-Unit-Networks.pdf"
  type: "long"
  spotlight: false
